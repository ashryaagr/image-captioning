{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vILc2k0ZcF0"
      },
      "source": [
        "import torch\n",
        "from torch import LongTensor\n",
        "from torch.nn import Embedding, LSTM\n",
        "from torch.autograd import Variable\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2Z1l7ovZzD0"
      },
      "source": [
        "# Decoder\n",
        "#credit: https://gist.githubusercontent.com/HarshTrivedi/f4e7293e941b17d19058f6fb90ab0fec/raw/60dc6be30ba57aa5d0d036e6af8ff702782ded18/pad_packed_demo.py\n",
        "## We want to run LSTM on a batch of 3 character sequences ['long_str', 'tiny', 'medium']\n",
        "#\n",
        "#     Step 1: Construct Vocabulary\n",
        "#     Step 2: Load indexed data (list of instances, where each instance is list of word indices)\n",
        "#     Step 3: Make Model\n",
        "#  *  Step 4: Pad instances with 0s till max length sequence\n",
        "#  *  Step 5: Sort instances by sequence length in descending order\n",
        "#  *  Step 6: Embed the instances\n",
        "#  *  Step 7: Call pack_padded_sequence with embeded instances and sequence lengths\n",
        "#  *  Step 8: Forward with LSTM\n",
        "#  *  Step 9: Call unpack_padded_sequences if required / or just pick last hidden vector\n",
        "#  *  Summary of Shape Transformations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIzKod1iZ521"
      },
      "source": [
        "# We want to run LSTM on a batch following 3 character sequences\n",
        "seqs = ['a small sentence',  # len = 3\n",
        "        'little bit bigger sentence',      # len = 4\n",
        "        'nothing to say']    # len = 3\n",
        "test = 'new word'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBj_Q7hxaFSc"
      },
      "source": [
        "## Step 1: Construct Vocabulary ##\n",
        "##------------------------------##\n",
        "# make sure <pad> idx is 0\n",
        "vocab = ['<pad>', '<start>', '<end>', '<unk>'] + sorted(set([word for seq in seqs for word in seq.split()]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YBFmR7OaU-D",
        "outputId": "06eccf6c-a02b-45fe-c25e-e0adaf79cdbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<pad>',\n",
              " '<start>',\n",
              " '<end>',\n",
              " '<unk>',\n",
              " 'a',\n",
              " 'bigger',\n",
              " 'bit',\n",
              " 'little',\n",
              " 'nothing',\n",
              " 'say',\n",
              " 'sentence',\n",
              " 'small',\n",
              " 'to']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed2zeu2saRJ-",
        "outputId": "7d3503ca-8656-4510-f7ff-311ebc870e5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "## Step 2: Load indexed data (list of instances, where each instance is list of character indices) ##\n",
        "##-------------------------------------------------------------------------------------------------##\n",
        "vectorized_seqs = [[vocab.index(tok) for tok in seq.split()]for seq in seqs]\n",
        "vectorized_seqs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[4, 11, 10], [7, 6, 5, 10], [8, 12, 9]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96m133RbaduM"
      },
      "source": [
        "## Step 3: Make Model ##\n",
        "##--------------------##\n",
        "embed = Embedding(len(vocab), 4) # embedding_dim = 4\n",
        "lstm = LSTM(input_size=4, hidden_size=5, num_layers = 1, batch_first=True) # input_dim = 4, hidden_dim = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHFPT15DakaG"
      },
      "source": [
        "## Step 4: Pad instances with 0s till max length sequence ##\n",
        "##--------------------------------------------------------##\n",
        "\n",
        "# get the length of each seq in your batch\n",
        "seq_lengths = LongTensor(list(map(len, vectorized_seqs)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIj1h-ZXg3kN",
        "outputId": "e8c0593e-ee68-4eaf-b711-9c780ebe9a4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "seq_lengths"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 4, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dz9rjmqeg2W2"
      },
      "source": [
        "# seq_lengths => [3, 4, 3]\n",
        "# batch_sum_seq_len: 3 + 4 + 3 = 10\n",
        "# max_seq_len: 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8hGYQQthDd9",
        "outputId": "5ded70a6-69e3-4e25-df36-c2bfc7706b3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "seq_tensor = Variable(torch.zeros((len(vectorized_seqs), seq_lengths.max()))).long()\n",
        "seq_tensor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0, 0],\n",
              "        [0, 0, 0, 0],\n",
              "        [0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfdIPYcKhIfC"
      },
      "source": [
        "for idx, (seq, seqlen) in enumerate(zip(vectorized_seqs, seq_lengths)):\n",
        "    seq_tensor[idx, :seqlen] = LongTensor(seq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mm82r_qthMCx",
        "outputId": "a3eeea1f-a019-443c-c534-24cb67c72197",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "seq_tensor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4, 11, 10,  0],\n",
              "        [ 7,  6,  5, 10],\n",
              "        [ 8, 12,  9,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ms1QmuGhqh-",
        "outputId": "7665d079-7f40-4276-bf84-8b9a6907d274",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "## Step 5: Sort instances by sequence length in descending order ##\n",
        "##---------------------------------------------------------------##\n",
        "\n",
        "seq_lengths, perm_idx = seq_lengths.sort(0, descending=True)\n",
        "seq_tensor = seq_tensor[perm_idx]\n",
        "seq_tensor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7,  6,  5, 10],\n",
              "        [ 4, 11, 10,  0],\n",
              "        [ 8, 12,  9,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wk2x_d8hwIA",
        "outputId": "53032583-f19b-444b-ba7e-d66a6c4ee445",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "## Step 6: Embed the instances ##\n",
        "##-----------------------------##\n",
        "\n",
        "embedded_seq_tensor = embed(seq_tensor)\n",
        "embedded_seq_tensor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.7504,  0.1101,  0.6357, -0.3962],\n",
              "         [ 0.5860,  0.1990, -1.1089, -0.9944],\n",
              "         [-0.7872, -0.0387, -0.3513,  1.4797],\n",
              "         [ 0.4854, -0.6458, -0.0287,  1.6919]],\n",
              "\n",
              "        [[-1.5781, -0.4140,  0.6682,  1.3491],\n",
              "         [-1.1741, -0.0588,  0.0357, -1.2057],\n",
              "         [ 0.4854, -0.6458, -0.0287,  1.6919],\n",
              "         [-1.2099, -1.0768, -0.6857,  0.6421]],\n",
              "\n",
              "        [[-0.0508,  1.1241, -0.3398, -1.4403],\n",
              "         [ 0.2659, -0.3261, -0.1594,  1.0797],\n",
              "         [ 0.0780, -0.0936,  0.0746, -1.2973],\n",
              "         [-1.2099, -1.0768, -0.6857,  0.6421]]], grad_fn=<EmbeddingBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wst8PO0_m4KW",
        "outputId": "3f8bef07-f26c-46d9-ebc7-88cd8769da38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "embedded_seq_tensor.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 4, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnOJumDBh4lE",
        "outputId": "a22f53bd-4a0b-41e1-af50-96da81c99f02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "## Step 7: Call pack_padded_sequence with embeded instances and sequence lengths ##\n",
        "##-------------------------------------------------------------------------------##\n",
        "\n",
        "packed_input = pack_padded_sequence(embedded_seq_tensor, seq_lengths.cpu().numpy(), batch_first=True)\n",
        "# packed_input (PackedSequence is NamedTuple with 2 attributes: data and batch_sizes\n",
        "packed_input.data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.7504,  0.1101,  0.6357, -0.3962],\n",
              "        [-1.5781, -0.4140,  0.6682,  1.3491],\n",
              "        [-0.0508,  1.1241, -0.3398, -1.4403],\n",
              "        [ 0.5860,  0.1990, -1.1089, -0.9944],\n",
              "        [-1.1741, -0.0588,  0.0357, -1.2057],\n",
              "        [ 0.2659, -0.3261, -0.1594,  1.0797],\n",
              "        [-0.7872, -0.0387, -0.3513,  1.4797],\n",
              "        [ 0.4854, -0.6458, -0.0287,  1.6919],\n",
              "        [ 0.0780, -0.0936,  0.0746, -1.2973],\n",
              "        [ 0.4854, -0.6458, -0.0287,  1.6919]],\n",
              "       grad_fn=<PackPaddedSequenceBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M7Q8d4kiEfd",
        "outputId": "74eed30e-8e9a-4855-9911-2bd04b3354f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "packed_input.data.shape #(batch_wise_sum_seq_len X embedding_dim) = (10 X 4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TQGYlSYnHFI",
        "outputId": "fd051b13-e4ce-4c89-a471-0fca2565db52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "packed_input.batch_sizes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 3, 3, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG9_OlwynL6R"
      },
      "source": [
        "# visualization :\n",
        "# little  bit    longer    sentence\n",
        "# a       small  sentence \n",
        "# nothing to     say\n",
        "# 3  3  3  1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdzNGPLHiAG0"
      },
      "source": [
        "# tensor([[-0.3227, -0.1044, -0.4612, -0.8055], #little\n",
        "#         [ 0.6384,  0.5617,  0.6570,  1.0578], #a\n",
        "#         [-0.7129,  0.3673,  0.0192, -0.4796], #nothing\n",
        "\n",
        "#         [-0.6661, -1.5316,  0.6446, -1.3370], #bit\n",
        "#         [-0.2879,  2.3274,  0.8726,  1.0885], #small\n",
        "#         [-0.1367, -0.2717, -0.2533, -1.3797], #to\n",
        "\n",
        "#         [-0.4653, -0.4362,  0.7046, -0.8728], #bigger\n",
        "#         [-0.3567, -0.0277,  1.1684,  0.8097], #sentence\n",
        "#         [ 0.9794, -0.4929, -1.6183, -0.6653], #say\n",
        "\n",
        "#         [-0.3567, -0.0277,  1.1684,  0.8097]]) #sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR947cXgnuYj"
      },
      "source": [
        "## Step 8: Forward with LSTM ##\n",
        "##---------------------------##\n",
        "\n",
        "packed_output, (ht, ct) = lstm(packed_input)\n",
        "# packed_output (PackedSequence is NamedTuple with 2 attributes: data and batch_sizes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOG-3vuDZ_rG"
      },
      "source": [
        "# ## Step 9: Call unpack_padded_sequences if required / or just pick last hidden vector ##\n",
        "# ##------------------------------------------------------------------------------------##\n",
        "\n",
        "# # unpack your output if required\n",
        "# output, input_sizes = pad_packed_sequence(packed_output, batch_first=True)\n",
        "\n",
        "# # output.shape : ( batch_size X max_seq_len X hidden_dim) = (3 X 4 X 5)\n",
        "\n",
        "# # Or if you just want the final hidden state?\n",
        "# print(ht[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcMmBpYUbiR7"
      },
      "source": [
        "## Summary of Shape Transformations ##\n",
        "##----------------------------------##\n",
        "\n",
        "# (batch_size X max_seq_len X embedding_dim) --> Sort by seqlen ---> (batch_size X max_seq_len X embedding_dim)\n",
        "# (batch_size X max_seq_len X embedding_dim) --->      Pack     ---> (batch_sum_seq_len X embedding_dim)\n",
        "# (batch_sum_seq_len X embedding_dim)        --->      LSTM     ---> (batch_sum_seq_len X hidden_dim)\n",
        "# (batch_sum_seq_len X hidden_dim)           --->    UnPack     ---> (batch_size X max_seq_len X hidden_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pgsZeKOoDcS"
      },
      "source": [
        "################ calculate loss ##############\n",
        "# there are two ways to calculate losses\n",
        "# using CrossEntropyLoss() = logSoftmax + NLLLoss()\n",
        "# using NLLLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDAgW99xoSCE"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axUEjCiypK8S"
      },
      "source": [
        "#lets assume for the sake of tutorial that targets = packed_input\n",
        "targets = seq_tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPxf21QupTcN",
        "outputId": "58109e5f-9dbe-4b44-a203-fa09c72ee137",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "targets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7,  6,  5, 10],\n",
              "        [ 4, 11, 10,  0],\n",
              "        [ 8, 12,  9,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyNEhuNuqKmR"
      },
      "source": [
        "targets = pack_padded_sequence(targets, seq_lengths.cpu().numpy(), batch_first=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA4ZsSloqak8",
        "outputId": "1c53bdc1-46c9-4a68-8000-75ddb4bea001",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "targets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PackedSequence(data=tensor([ 7,  4,  8,  6, 11, 12,  5, 10,  9, 10]), batch_sizes=tensor([3, 3, 3, 1]), sorted_indices=None, unsorted_indices=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sDMajifp03_"
      },
      "source": [
        "linear = nn.Linear(5, len(vocab)) #hidden_size, vocab_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8sopE0ep-ev"
      },
      "source": [
        "outputs = linear(packed_output.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQwHMX97qvxw",
        "outputId": "2cf4738f-0486-4cad-9ead-f98271752673",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "outputs.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 13])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ojhyYLMo6di",
        "outputId": "3b88ede1-ea9b-4cde-d1f6-4fffb3ba885f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "loss = criterion(outputs, targets.data) \n",
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.5527, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8aDT7sApKQG",
        "outputId": "a9dee345-761d-491f-c8bd-83e072857287",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "criterion_2 = nn.NLLLoss()\n",
        "loss = criterion(F.log_softmax(outputs, dim=1), targets.data) \n",
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.5527, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCy26IYqrLBK"
      },
      "source": [
        "########### Generation #################\n",
        "# For generating, you will want to generate one word at a time, but for tutorial's sake we are reusing the outputs generated above \n",
        "# to dicuss the main difference between two approaches."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD1E1lr_rn4C"
      },
      "source": [
        "# Deterministic: get the maximum output from output at each step of generation\n",
        "_, predicted = outputs.max(1)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNX-85RMtixb",
        "outputId": "7b177351-4524-4096-e3fa-04e96edf74dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "predicted"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4, 4, 4, 3, 4, 4, 4, 4, 4, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADGPTOjztBsk"
      },
      "source": [
        "# Stochastic: sample from weighted softmax distribution\n",
        "temperature = 1\n",
        "probabilities = F.softmax(outputs.div(temperature).squeeze(0).squeeze(0), dim=1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nydZcTrEtWIT",
        "outputId": "872b699e-e14e-4ac5-df74-d984b1bdf362",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "probabilities"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0556, 0.0627, 0.0468, 0.0957, 0.1069, 0.0886, 0.0839, 0.0812, 0.0944,\n",
              "         0.0692, 0.0480, 0.0744, 0.0925],\n",
              "        [0.0512, 0.0638, 0.0502, 0.0884, 0.1183, 0.0891, 0.0934, 0.0711, 0.0910,\n",
              "         0.0690, 0.0461, 0.0717, 0.0965],\n",
              "        [0.0514, 0.0653, 0.0462, 0.0967, 0.1059, 0.0994, 0.0814, 0.0704, 0.1006,\n",
              "         0.0757, 0.0417, 0.0768, 0.0886],\n",
              "        [0.0575, 0.0613, 0.0431, 0.1086, 0.0987, 0.0893, 0.0787, 0.0858, 0.0953,\n",
              "         0.0700, 0.0507, 0.0765, 0.0844],\n",
              "        [0.0467, 0.0676, 0.0498, 0.0846, 0.1228, 0.1004, 0.0882, 0.0590, 0.0955,\n",
              "         0.0756, 0.0396, 0.0738, 0.0964],\n",
              "        [0.0506, 0.0602, 0.0439, 0.0945, 0.1044, 0.0948, 0.0914, 0.0766, 0.0966,\n",
              "         0.0700, 0.0450, 0.0769, 0.0951],\n",
              "        [0.0495, 0.0598, 0.0446, 0.0953, 0.1056, 0.0944, 0.0961, 0.0747, 0.0954,\n",
              "         0.0697, 0.0451, 0.0759, 0.0939],\n",
              "        [0.0474, 0.0583, 0.0430, 0.0898, 0.1115, 0.0942, 0.1003, 0.0722, 0.0915,\n",
              "         0.0676, 0.0465, 0.0761, 0.1015],\n",
              "        [0.0520, 0.0637, 0.0449, 0.0965, 0.1077, 0.0963, 0.0828, 0.0730, 0.0970,\n",
              "         0.0730, 0.0448, 0.0768, 0.0915],\n",
              "        [0.0496, 0.0564, 0.0420, 0.0938, 0.1036, 0.0914, 0.1004, 0.0805, 0.0928,\n",
              "         0.0660, 0.0480, 0.0766, 0.0990]], grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P66dfe2atNGY",
        "outputId": "73c3b83b-aa33-46fb-c810-012f1dfbb39b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "predicted = torch.multinomial(probabilities.data, 1)\n",
        "predicted"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6],\n",
              "        [1],\n",
              "        [9],\n",
              "        [4],\n",
              "        [8],\n",
              "        [8],\n",
              "        [3],\n",
              "        [2],\n",
              "        [1],\n",
              "        [6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkcuXzOVteiK",
        "outputId": "3e4c0329-de26-447c-b48a-6af8159435ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "predicted = torch.multinomial(probabilities.data, 1)\n",
        "predicted"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4],\n",
              "        [ 8],\n",
              "        [ 6],\n",
              "        [ 3],\n",
              "        [ 4],\n",
              "        [ 3],\n",
              "        [ 1],\n",
              "        [10],\n",
              "        [ 5],\n",
              "        [ 6]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbZsG2buwGYB"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}